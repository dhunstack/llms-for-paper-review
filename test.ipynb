{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read both human and LLM JSONL files\n",
    "df_human = pd.read_json('./data/ReviewCritique.jsonl', lines=True)\n",
    "df_llm = pd.read_json('./data/ReviewCritique_LLM.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['decision', 'title', 'body_text', 'claude_opus', 'gpt4',\n",
       "       'gemini_pro_1.5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_llm has title, and 3 review columns 'claude_opus', 'gpt4', 'gemini_pro_1.5'\n",
    "df_llm.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['decision', 'title', 'body_text', 'review#1', 'review#2', 'review#3',\n",
       "       'review#4', 'review#5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_human has 5 review columns, but we will use only three 'review#1', 'review#2', 'review#3'\n",
    "df_human.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First check which titles occur in both df_llm and df_human\n",
    "# Should be 20 total based on our understanding\n",
    "# Right now we only get 15, but we'll proceed with that\n",
    "df_human['title'] = [t.lower() for t in df_human['title']]\n",
    "df_llm['title'] = [t.lower() for t in df_llm['title']]\n",
    "\n",
    "common_titles = df_llm['title'].isin(df_human['title'])\n",
    "sum(common_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_llm_filtered = df_llm[common_titles]\n",
    "df_human_filtered = df_human[df_human['title'].isin(df_llm['title'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directory structure\n",
    "# We keep one folder for all the review data\n",
    "# The root folder is called 'extracted'\n",
    "# Each paper has its own subfolder in this root, with the title of the paper as the folder name\n",
    "# Each paper folder has three subfolders inside, one for actual reviews, one for pairwise and one for summarised\n",
    "# Actual reviews will have 3 human and 3 LLM original reviews.\n",
    "# Summarised will have same 6 reviews summarised in bullet points by another LLM\n",
    "# Pairwise will have 6C2 i.e. 15 pairwise comparisons for all the reviews\n",
    "\n",
    "import os\n",
    "FOLDER_PATH = './extracted/'\n",
    "\n",
    "for title in df_llm_filtered.title:\n",
    "    folder_name = title.replace(' ', '_')\n",
    "    try:\n",
    "        os.makedirs(FOLDER_PATH + folder_name)\n",
    "        os.makedirs(FOLDER_PATH + folder_name + '/actual')\n",
    "        os.makedirs(FOLDER_PATH + folder_name + '/summarised')\n",
    "        os.makedirs(FOLDER_PATH + folder_name + '/pairwise')\n",
    "    except:\n",
    "        pass\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we parse the original reviews for both humans and LLMs\n",
    "for idx, paper in df_human_filtered.iterrows():\n",
    "    # Get review texts\n",
    "    review1 = '\\n'.join([review['segment_text'] for review in paper['review#1']['review']])\n",
    "    review2 = '\\n'.join([review['segment_text'] for review in paper['review#2']['review']])\n",
    "    review3 = '\\n'.join([review['segment_text'] for review in paper['review#3']['review']])\n",
    "\n",
    "    # Store the reviews in file\n",
    "    folder_name = paper['title'].replace(' ', '_')\n",
    "    \n",
    "    with open(os.path.join('extracted', folder_name, 'actual', 'review1.txt'), 'w') as file1:\n",
    "        file1.write(review1)\n",
    "    \n",
    "    with open(os.path.join('extracted', folder_name, 'actual', 'review2.txt'), 'w') as file2:\n",
    "        file2.write(review2)\n",
    "    \n",
    "    with open(os.path.join('extracted', folder_name, 'actual', 'review3.txt'), 'w') as file3:\n",
    "        file3.write(review3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we parse the original reviews for both humans and LLMs\n",
    "for idx, paper in df_llm_filtered.iterrows():\n",
    "    # Get review texts\n",
    "    claude_opus = '\\n'.join([review['segment_text'] for review in paper['claude_opus']['review']])\n",
    "    gpt4 = '\\n'.join([review['segment_text'] for review in paper['gpt4']['review']])\n",
    "    gemini_pro = '\\n'.join([review['segment_text'] for review in paper['gemini_pro_1.5']['review']])\n",
    "\n",
    "    # Store the reviews in file\n",
    "    folder_name = paper['title'].replace(' ', '_')\n",
    "    \n",
    "    with open(os.path.join('extracted', folder_name, 'actual', 'claude_opus.txt'), 'w') as file1:\n",
    "        file1.write(claude_opus)\n",
    "    \n",
    "    with open(os.path.join('extracted', folder_name, 'actual', 'gpt4.txt'), 'w') as file2:\n",
    "        file2.write(gpt4)\n",
    "    \n",
    "    with open(os.path.join('extracted', folder_name, 'actual', 'gemini_pro.txt'), 'w') as file3:\n",
    "        file3.write(gemini_pro)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get LLM Summaries for all Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "review",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
