Summary of the Paper:
This paper introduces WebBrain, a new NLP task focused on generating short, factual articles for queries by mining supporting evidence from the web.
The paper also presents WebBrain-Raw, a large-scale dataset built from Wikipedia articles and their references, and ReGen, a framework designed to improve factual correctness in generated articles.
ReGen utilizes a sparse lexical model (SPLADE) for evidence retrieval and a sequence-to-sequence model with Fusion-in-Decoder (FiD) architecture for text generation.
The paper compares ReGen to several baselines and demonstrates its superior performance through automatic and human evaluations.
Strengths and Weaknesses:
Strengths:
Novel and valuable task: WebBrain addresses the challenge of generating factual articles, which has significant potential for applications like automatic Wikipedia page creation, writing assistance, and knowledge-intensive QA.
Large-scale dataset: WebBrain-Raw is ten times larger than similar datasets, providing a valuable resource for research on this task.
Improved factual correctness: ReGen's focus on evidence retrieval and task-specific pre-training leads to demonstrably more factual articles compared to baselines.
Detailed analysis: The paper provides a thorough analysis of the task, dataset, and model performance, including comparisons with different retrievers and varying numbers of references.
Weaknesses:
Retrieval quality: While ReGen shows improvement, the reliance on retrieved evidence still leads to performance below that achieved with gold references, highlighting the need for further advancements in retrieval quality.
Reference mark accuracy: The current model struggles to accurately identify the source of information for generated sentences, impacting factualness and readability.
Limited article length: The current focus is on generating short articles, whereas full Wikipedia pages contain much more information.
Generating longer, comprehensive articles remains a challenge.
Clarity, Quality, Novelty, and Reproducibility:
Clarity: The paper is well-written and clearly presents the task, dataset, and model architecture.
Quality: The research is well-designed and executed, with comprehensive experiments and analysis.
Novelty: WebBrain is a novel task, and ReGen introduces new strategies for improving factual correctness in generated articles.
Reproducibility: The paper provides implementation details and plans to release the datasets upon acceptance, facilitating reproducibility.
Summary of the Review:
This paper presents a valuable contribution to the field of NLP by introducing WebBrain, a novel and challenging task with significant potential applications.
The proposed ReGen framework shows promising results in improving factual correctness, although challenges remain in retrieval quality and reference mark accuracy.
Future work should focus on addressing these limitations and expanding the task to generate longer, more comprehensive articles.